<div class="hero-icon" align="center">
  <img src="https://raw.githubusercontent.com/PKief/vscode-material-icon-theme/ec559a9f6bfd399b82bb44393651661b08aaf7ba/icons/folder-markdown-open.svg" width="100" />
</div>

<h1 align="center">
AI Query Response Backend - MVP
</h1>
<h4 align="center">A Python-based backend service for integrating OpenAI language models into applications.</h4>
<h4 align="center">Developed with the software and tools below.</h4>
<div class="badges" align="center">
  <img src="https://img.shields.io/badge/Language-Python-blue" alt="Programming Language" />
  <img src="https://img.shields.io/badge/Framework-FastAPI-red" alt="Web Framework" />
  <img src="https://img.shields.io/badge/Database-PostgreSQL-blue" alt="Database" />
  <img src="https://img.shields.io/badge/AI-OpenAI-black" alt="AI Service" />
</div>
<div class="badges" align="center">
  <img src="https://img.shields.io/github/last-commit/coslynx/AI-Query-Response-Backend-MVP?style=flat-square&color=5D6D7E" alt="git-last-commit" />
  <img src="https://img.shields.io/github/commit-activity/m/coslynx/AI-Query-Response-Backend-MVP?style=flat-square&color=5D6D7E" alt="GitHub commit activity" />
  <img src="https://img.shields.io/github/languages/top/coslynx/AI-Query-Response-Backend-MVP?style=flat-square&color=5D6D7E" alt="GitHub top language" />
</div>

## ğŸ“‘ Table of Contents
- ğŸ“ Overview
- ğŸ“¦ Features
- ğŸ“‚ Structure
- ğŸ’» Installation
- ğŸ—ï¸ Usage
- ğŸŒ Hosting
- ğŸ“„ License
- ğŸ‘ Authors

## ğŸ“ Overview

This repository houses a Minimum Viable Product (MVP) called "AI-Query-Response-Backend-MVP" designed to simplify the integration of OpenAI's language models into various applications. This MVP empowers developers and businesses to seamlessly connect their applications with powerful AI capabilities, unlocking a world of possibilities for natural language processing, text generation, and query resolution.

## ğŸ“¦ Features

|    | Feature            | Description                                                                                                        |
|----|--------------------|--------------------------------------------------------------------------------------------------------------------|
| âš™ï¸ | **Architecture**   | The MVP follows a modular architectural pattern, organizing code into logical directories and modules for improved maintainability and scalability. |
| ğŸ“„ | **Documentation**  | This README file provides a comprehensive overview of the MVP, including installation instructions, API details, and examples of usage.        |
| ğŸ”— | **Dependencies**   | The project utilizes a well-defined set of dependencies, including FastAPI for web development, SQLAlchemy for database interactions, and the official OpenAI Python library for accessing OpenAI's powerful models.    |
| ğŸ§© | **Modularity**     | The codebase is designed to be highly modular, with separate modules for core functionalities like authentication, database interactions, and query processing. |
| ğŸ§ª | **Testing**        | The MVP includes a comprehensive test suite to ensure code quality, reliability, and functionality.                                 |
| âš¡ï¸  | **Performance**    | The backend service is optimized for efficient processing of requests and responses.                                |
| ğŸ”’ | **Security**       | Robust security measures are implemented, including secure authentication and data handling practices to protect user data and ensure responsible AI usage. |
| ğŸ”„ | **Scalability**     | The backend architecture is designed to handle growing volumes of requests and responses, ensuring scalability to support increasing user demand. |
| ğŸ”Œ | **Integrations**   | The backend seamlessly integrates with external applications through well-defined APIs and messaging protocols.                         |

## ğŸ“‚ Structure

```text
api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth_schema.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â””â”€â”€ auth_utils.py
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â””â”€â”€ db_utils.py
â”‚   â”‚   â”œâ”€â”€ query/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query_schema.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â””â”€â”€ query_utils.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_router.py
â”‚   â”‚   â”‚   â””â”€â”€ query_router.py
â”‚   â”‚   â”œâ”€â”€ exceptions/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ base_exception.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ common_utils.py
â”‚   â”‚   â”‚   â””â”€â”€ openai_utils.py
â”‚   â”‚   â””â”€â”€ dependencies.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ startup.sh
â””â”€â”€ commands.json

```

## ğŸ’» Installation

### ğŸ”§ Prerequisites
- Python 3.9+
- PostgreSQL 13+
- Docker

### ğŸš€ Setup Instructions
1. Clone the repository:
   ```bash
   git clone https://github.com/coslynx/AI-Query-Response-Backend-MVP.git
   cd AI-Query-Response-Backend-MVP
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Set up the database:
   ```bash
   docker-compose up -d db
   ```
4. Configure environment variables:
   ```bash
   cp .env.example .env
   # Fill in the necessary environment variables (OPENAI_API_KEY, DATABASE_URL, JWT_SECRET_KEY)
   ```

## ğŸ—ï¸ Usage

### ğŸƒâ€â™‚ï¸ Running the MVP
1. Start the development server:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000 --reload
   ```

### âš™ï¸ Configuration
- **`.env`:** This file contains environment variables like API keys, database connection strings, and secret keys.
- **`src/config/settings.py`:** This file defines application-wide settings, including database configurations, API settings, and authentication parameters.

### ğŸ“š Examples
```python
# Send a query to the API
import requests

url = "http://localhost:8000/query"
headers = {"Content-Type": "application/json"}
data = {"query": "What is the meaning of life?", "model": "text-davinci-003"}

response = requests.post(url, headers=headers, json=data)

if response.status_code == 200:
  print(response.json())
else:
  print("Error:", response.text)
```

## ğŸŒ Hosting

### ğŸš€ Deployment Instructions

1. **Build the Docker image:**
   ```bash
   docker build -t ai-query-backend .
   ```
2. **Run the application in a Docker container:**
   ```bash
   docker run -p 8000:8000 ai-query-backend
   ```

### ğŸ”‘ Environment Variables
- `OPENAI_API_KEY`: Your OpenAI API key.
- `DATABASE_URL`: Your PostgreSQL database connection string.
- `JWT_SECRET_KEY`: A secret key for JWT authentication.

## ğŸ“œ API Documentation

### ğŸ” Endpoints

- **POST `/query`**:
    - Description: Processes a user query using OpenAI's API and returns the generated response.
    - Body:
        ```json
        {
          "query": "Your query here",
          "model": "The OpenAI model to use (e.g., 'text-davinci-003')"
        }
        ```
    - Response:
        ```json
        {
          "query_id": "The ID of the processed query",
          "response": "The AI-generated response"
        }
        ```

- **POST `/login`**:
    - Description: Authenticates a user and returns a JWT access token.
    - Body:
        ```json
        {
          "email": "Your email address",
          "password": "Your password"
        }
        ```
    - Response:
        ```json
        {
          "access_token": "The JWT access token",
          "token_type": "bearer"
        }
        ```

### ğŸ”’ Authentication

- The API uses JWT authentication for protected endpoints.
- To access protected endpoints, include the JWT access token in the `Authorization` header of requests, using the format `Bearer <token>`.

## ğŸ“œ License & Attribution

### ğŸ“„ License
This Minimum Viable Product (MVP) is licensed under the [GNU AGPLv3](https://choosealicense.com/licenses/agpl-3.0/) license.

### ğŸ¤– AI-Generated MVP
This MVP was entirely generated using artificial intelligence through [CosLynx.com](https://coslynx.com).

No human was directly involved in the coding process of the repository: AI-Query-Response-Backend-MVP

### ğŸ“ Contact
For any questions or concerns regarding this AI-generated MVP, please contact CosLynx at:
- Website: [CosLynx.com](https://coslynx.com)
- Twitter: [@CosLynxAI](https://x.com/CosLynxAI)

<p align="center">
  <h1 align="center">ğŸŒ CosLynx.com</h1>
</p>
<p align="center">
  <em>Create Your Custom MVP in Minutes With CosLynxAI!</em>
</p>
<div class="badges" align="center">
  <img src="https://img.shields.io/badge/Developers-Drix10,_Kais_Radwan-red" alt="">
  <img src="https://img.shields.io/badge/Website-CosLynx.com-blue" alt="">
  <img src="https://img.shields.io/badge/Backed_by-Google,_Microsoft_&_Amazon_for_Startups-red" alt="">
  <img src="https://img.shields.io/badge/Finalist-Backdrop_Build_v4,_v6-black" alt="">
</div>